{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Restore model from checkpoint.<br>\n",
    "2. Evaluate word embeddings using closest words.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lance\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gensim\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sg_model_fn(features, labels, mode):\n",
    "    with tf.name_scope(\"embeddings\"):\n",
    "        embeddings = tf.get_variable(\"embedding\", shape=[vocab_size, emb_dim])\n",
    "        embed = tf.nn.embedding_lookup(embeddings, features[\"word\"])\n",
    "        print(\"Embedded shape:\", embed.shape)\n",
    "    with tf.name_scope(\"weights\"):\n",
    "        nce_weights = tf.get_variable(\"W\", shape=[vocab_size, emb_dim])\n",
    "        print(\"nce_weights shape:\", nce_weights.shape)\n",
    "    with tf.name_scope(\"biases\"):\n",
    "        nce_biases = tf.get_variable(\"b\", shape=[vocab_size])\n",
    "        print(\"nce_biases shape:\", nce_biases.shape)\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        loss = tf.reduce_mean(tf.nn.nce_loss(\n",
    "            weights=nce_weights, biases=nce_biases,\n",
    "            inputs=embed, labels=labels[:, None], \n",
    "            num_sampled=5, num_classes=vocab_size))\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3489467\n",
      "3489467\n"
     ]
    }
   ],
   "source": [
    "# read word indexes\n",
    "index2word = {}\n",
    "word2index = {}\n",
    "with open(r\"D:\\stocktwits_text\\2018 all\\word_index.csv\", \"r\", encoding=\"utf-8\") as in_f:\n",
    "    for row in csv.reader(in_f):\n",
    "        index2word[int(row[1])] = row[0]\n",
    "        word2index[row[0]] = int(row[1])\n",
    "print(len(index2word))\n",
    "print(len(word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model_dir):\n",
    "    # Copy model definition and classifier configuration from the training code\n",
    "    strategy = tf.contrib.distribute.MirroredStrategy(num_gpus=2, prefetch_on_device=True)\n",
    "    config = tf.estimator.RunConfig(\n",
    "        save_summary_steps=200,\n",
    "        train_distribute=strategy,\n",
    "        save_checkpoints_secs = 20*60,\n",
    "        keep_checkpoint_max = 3,\n",
    "        model_dir=model_dir)\n",
    "    classifier = tf.estimator.Estimator(model_fn=sg_model_fn, \n",
    "                                        config=config)\n",
    "    print(\"Lastest checkpoint:\", classifier.latest_checkpoint())\n",
    "    print(\"Current global step:\", classifier.get_variable_value(\"global_step\"))\n",
    "    print(\"Variable names:\", classifier.get_variable_names())\n",
    "    \n",
    "    fixed_words = [\"bull\", \"bullish\", \"bear\", \"bearish\", \"breakout\", \"bottom\", \"bounce\", \"short\", \"rally\", \"strength\",\n",
    "                   \"nice\", \"dip\",\"puts\",\"aapl\",\"down\",\"earnings\", \"dividend\", \"subpoena\", \"estimate\", \"volume\", \"risk\",\n",
    "                   \":)\", \"<rocket>\", \":(\", \"<fire>\"]\n",
    "    fixed_examples = [word2index[w] for w in fixed_words]\n",
    "    valid_size = 16               # Random set of words to evaluate similarity on.\n",
    "    valid_window = 100\n",
    "\n",
    "    embeddings = classifier.get_variable_value(\"embedding\")\n",
    "    # pick 8 samples from (0,100) and (1000,1100) each ranges. lower id implies more frequent \n",
    "    valid_examples = np.array(random.sample(range(valid_window), valid_size//2))\n",
    "    valid_examples = np.append(valid_examples, \n",
    "                               random.sample(range(1000,1000+valid_window), valid_size//2))\n",
    "    valid_examples = np.append(valid_examples, fixed_examples)\n",
    "    norm_embed = normalize(embeddings)\n",
    "    valid_embed = np.vstack(list(map(lambda x: norm_embed[x], valid_examples)))\n",
    "    similarity = np.matmul(valid_embed, np.transpose(norm_embed))\n",
    "\n",
    "    for i in range(len(valid_examples)):\n",
    "        valid_word = index2word[valid_examples[i]]\n",
    "        top_k = 8 # number of nearest neighbors\n",
    "        nearest = (-similarity[i, :]).argsort()[1:top_k+1]\n",
    "        log = '%12s:\\t' % valid_word\n",
    "        for k in range(top_k):\n",
    "            close_word = index2word[nearest[k]]\n",
    "            log = '%s %s,' % (log, close_word)\n",
    "        print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'F:\\\\w2v_model_dir', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 1200, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x0000026A1D837390>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000026A1D8374E0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n",
      "Lastest checkpoint: F:\\w2v_model_dir\\model.ckpt-87852\n",
      "Current global step: 87852\n",
      "Variable names: ['W', 'W/Adam', 'W/Adam_1', 'b', 'b/Adam', 'b/Adam_1', 'beta1_power', 'beta2_power', 'embedding', 'embedding/Adam', 'embedding/Adam_1', 'global_step']\n",
      "       today:\t afterhour, premkt, tday, after-hour, afterhours, moday, <sym>, tomorro,\n",
      "           a:\t acad, muti, ptn, igc, omer, trem, nete, bzun,\n",
      "         are:\t aren't, arent, were, arnt, projecting, weren't, they're, werent,\n",
      "           s:\t ’, `, ´, macy, ain, ', n, here,\n",
      "           (:\t ), rydex, cls, lon, esh, :op, nysearca, #swing,\n",
      "      <user>:\t yeh, yea, naa, ik, yah, haha, yeha, yeah,\n",
      "          be:\t surely, suffice, definitely, ensue, suprise, probably, start, materialize,\n",
      "        time:\t tine, tome, tme, weeknd, 0ies, june-july, highes, 0mons,\n",
      " <thumbs_up>:\t <thumbs_up_light_skin_tone>, <ok_hand>, <thumbs_up_medium-light_skin_tone>, <smiling_face_with_sunglasses>, <thumbs_up_medium_skin_tone>, <smiling_face_with_smiling_eyes>, <folded_hands>, <clinking_beer_mugs>,\n",
      "     chinese:\t mj, marijuana, airline, crypto, tech, shipping, greek, wearables,\n",
      "     heading:\t headed, retracing, edging, reversing, drifting, inching, marching, stabilizing,\n",
      "       meant:\t ment, sry, mean't, misspoke, mistyped, yeh, dunno, needless,\n",
      "        safe:\t prudent, unwise, enticing, wise, precise, advisable, balanced, tern,\n",
      "         0nd:\t 0rd, 0st, final, november, october, september, august, december,\n",
      "       heavy:\t exhausted, heavier, tightly, upticks, nibbling, outweighing, thin, churning,\n",
      "       worst:\t biggest, greatest, strangest, best, longest, weirdest, toughest, craziest,\n",
      "        bull:\t bear, homing, textbook, engulf, trap, saucer, penant, hns,\n",
      "     bullish:\t bearish, leaning, overbought, homing, constructive, crossovers, indecisive, heikin,\n",
      "        bear:\t bull, shark, trap, homing, hollow, pigeon, crab, flaggy,\n",
      "     bearish:\t bullish, crossovers, overbought, candlesticks, constructive, oscillator, homing, renko,\n",
      "    breakout:\t reversal, continuation, breakdown, piercing, pennant, kumo, bullflag, flagging,\n",
      "      bottom:\t btm, decending, prz, backtest, exhaustion, rejection, 0wma, floor,\n",
      "      bounce:\t re-test, rebound, pull-back, deadcat, pullback, retrace, test, retest,\n",
      "       short:\t shrt, sml, daytrade, positional, ★, trm, posn, uco,\n",
      "       rally:\t rebound, sell-off, selloff, recovery, short-covering, whipsaw, snapback, swoon,\n",
      "    strength:\t weakness, indecision, momentum, breadth, divergent, reversals, longer-term, breakouts,\n",
      "        nice:\t lovely, sweet, tasty, juicy, fantastic, great, beautiful, bouncer,\n",
      "         dip:\t dipper, afternoon, gap-up, lunchtime, morn, re-load, pop, leap,\n",
      "        puts:\t calls, itm, weeklies, otm, leaps, ditm, 0calls, lottos,\n",
      "        aapl:\t amzn, nflx, twtr, baba, nvda, tsla, mu, celg,\n",
      "        down:\t up, uo, donw, kospi, fown, dowm, to0, dwn,\n",
      "    earnings:\t earning, thursday, wednesday, er, tuesday, after, ex-div, 0q,\n",
      "    dividend:\t aristocrat, putnam, semiannual, reinvestment, series, nuveen, buy-write, costamare,\n",
      "    subpoena:\t whistleblower, foia, prosecutor, investigator, investigators, commissioner, subpoenas, investigative,\n",
      "    estimate:\t projection, forcast, exceeded, estimation, concensus, dau, subscriber, narrowed,\n",
      "      volume:\t unusually, volum, cumulative, volumes, mvg, short, volumn, #volume,\n",
      "        risk:\t tolerance, reward, favors, outweighs, appetite, aversion, averse, liquidity,\n",
      "          :):\t :-), ;), =), ;-), (:, :d, :], :-d,\n",
      "    <rocket>:\t <collision>, <fire>, <chart_increasing>, <dollar_banknote>, <money_bag>, <volcano>, <flexed_biceps_light_skin_tone>, <flexed_biceps_medium-light_skin_tone>,\n",
      "          :(:\t :-(, ;(, =(, :'(, ugh, :-/, ;-(, grrr,\n",
      "      <fire>:\t <collision>, <rocket>, <heavy_dollar_sign>, <chart_increasing>, <dollar_banknote>, <money_bag>, <volcano>, <water_buffalo>,\n"
     ]
    }
   ],
   "source": [
    "evaluate(r\"F:\\w2v_model_dir\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'F:\\\\w2v_model_dir_8192', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 1200, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x0000026A1D837320>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000026A1D837518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n",
      "Lastest checkpoint: F:\\w2v_model_dir_8192\\model.ckpt-702810\n",
      "Current global step: 702810\n",
      "Variable names: ['W', 'W/Adam', 'W/Adam_1', 'b', 'b/Adam', 'b/Adam_1', 'beta1_power', 'beta2_power', 'embedding', 'embedding/Adam', 'embedding/Adam_1', 'global_step']\n",
      "          go:\t rolll, zigs, pust, bi's, shoot, tripples, goup, sprawl,\n",
      "       stock:\t stk, tilray, stock.the, valua, qre, stcok, tlry, inspur,\n",
      "          me:\t him, us, them, junk-rated, squinty, rqst, kubaw, juncker's,\n",
      "           %:\t ℅, in-line.revenue, 0percent, 0pct, consensu, 0.0, yty, ex-energy,\n",
      "         now:\t tagets, off-the-charts, evy, jacquie, commoditiy, assortments, lionsgate's, roadways,\n",
      "       today:\t #lnco, daimler's, time-tested, 0mr, colcap, #thc, #asco, #avp,\n",
      "          if:\t when, unless, whether, whenever, 0if, nevers, 0.if, #opportunitycost,\n",
      "         and:\t contigency, f-r, institutionnal, super-size, kad, heelys, ipx, itno,\n",
      "           â:\t ˜, , ¦, ð, ð½ð, œ, italyâ, æ,\n",
      "         aug:\t oct, nov, sep, feb, dec, jan, mar, apr,\n",
      "      bigger:\t larger, smaller, gigantic, huge, greater, big, quicker, tiny,\n",
      "     history:\t hx, repeats, choppiest, 0.same, hypersensitivity, truthfulness, #graphite, qnx's,\n",
      "      latest:\t lastest, factsheet, newest, #wsjexperts, marder's, recapping, embargoed, detailing,\n",
      "       it'll:\t itll, this'll, she'll, will, they'll, we'll, that'll, he'll,\n",
      "      you'll:\t youll, ull, u'll, they'll, we'll, he'll, i'll, youl,\n",
      "    products:\t product, designs, biossance, cpu's, gpu's, gpus, motherboards, technology,\n",
      "        bull:\t bear, raging, flag, perma, secular, trap, traps, falg,\n",
      "     bullish:\t bearish, bulish, bearis, optimistic, bullis, beari, bullush, englufing,\n",
      "        bear:\t bull, raging, perma, trap, teddy, traps, trappy, pooh,\n",
      "     bearish:\t bullish, bulish, bearis, negative, beari, bullis, bullush, engulfings,\n",
      "    breakout:\t break-out, breakdown, reversal, cup-with-handle, bullflag, pennant, vcp, bull-flag,\n",
      "      bottom:\t top, bottoms, btm, floor, entendre, botton, bottome, buttom,\n",
      "      bounce:\t bounces, rebound, retrace, bouce, cat, dcb, deadcat, bouncing,\n",
      "       short:\t shrt, shorter, shorts, shorting, farkers, pre-lim, shorty, #morningstar,\n",
      "       rally:\t selloff, sell-off, rebound, meltdown, snap-back, short-covering, resurge, swoon,\n",
      "    strength:\t weakness, strenght, resilience, strengh, weekness, resiliency, relative, stength,\n",
      "        nice:\t lovely, awesome, sweet, beautiful, fantastic, great, fabulous, decent,\n",
      "         dip:\t dips, dipppp, deeps, dippage, spike, dipper, kippur, pulllback,\n",
      "        puts:\t calls, weeklies, leaps, itm, lottos, otm, ditm, 0calls,\n",
      "        aapl:\t nflx, amzn, appl, msft, googl, goog, baba, nvda,\n",
      "        down:\t up, dwn, diwn, dowm, uo, doen, down.lol, re-weighting,\n",
      "    earnings:\t earning, er, earnigs, earrings, earings, computex, earning's, earnigns,\n",
      "    dividend:\t dividends, divy, divi, div, divvy, dividen, payout, yield,\n",
      "    subpoena:\t subpoenas, whistleblower, doj, inquiry, rescind, allegation, alleging, appellate,\n",
      "    estimate:\t projection, estimation, projections, expectation, estimated, projected, guesstimate, forcast,\n",
      "      volume:\t volumes, volumn, vol, voume, volum, volumne, colume, vollume,\n",
      "        risk:\t reward, risks, gamble, tolerance, asymmetric, diversification, tradeoff, risking,\n",
      "          :):\t :-), ;), ;-), =), <winking_face>, <smiling_face_with_smiling_eyes>, <slightly_smiling_face>, <beaming_face_with_smiling_eyes>,\n",
      "    <rocket>:\t <collision>, <chart_increasing>, <airplane_departure>, <money_with_wings>, <heavy_dollar_sign>, <money-mouth_face>, <dollar_banknote>, <fire>,\n",
      "          :(:\t :-(, ugh, :/, ;(, <pensive_face>, :'(, <disappointed_face>, fml,\n",
      "      <fire>:\t <collision>, <heavy_dollar_sign>, <rocket>, <chart_increasing>, <money_with_wings>, <bomb>, <money-mouth_face>, <comet>,\n"
     ]
    }
   ],
   "source": [
    "evaluate(r\"F:\\w2v_model_dir_8192\") # batch_size = 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'F:\\\\w2v_model_dir_8192_shuffle', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 1200, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x0000026A1D837518>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000026A1D8379B0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n",
      "Lastest checkpoint: F:\\w2v_model_dir_8192_shuffle\\model.ckpt-351405\n",
      "Current global step: 351405\n",
      "Variable names: ['W', 'W/Adam', 'W/Adam_1', 'b', 'b/Adam', 'b/Adam_1', 'beta1_power', 'beta2_power', 'embedding', 'embedding/Adam', 'embedding/Adam_1', 'global_step']\n",
      "        long:\t ling, looooong, looong, loooong, loooooong, lomg, mid-long, longterm,\n",
      "        it's:\t everything's, i'ts, this's, that's, its, isn't, they're, theyre,\n",
      "          it:\t that, iit, she, jt, iy, ot, tlry, prettt,\n",
      "          or:\t perhaps, maybe, rmore, #nonews, orrrr, mybe, overnigh, colgate's,\n",
      "          if:\t unless, when, iif, hope, whether, 0.if, assuming, 0if,\n",
      "         not:\t nit, isn't, mot, isnt, nkt, noy, idk, expecring,\n",
      "          do:\t donyou, d'you, indont, idont, dou, do.you, domt, did,\n",
      "        good:\t gud, great, gd, goood, goid, gr0, terrible, bad,\n",
      "    downside:\t upside, dwnside, upsides, headroom, slippage, near-term, dowside, asymmetric,\n",
      "         0nd:\t 0rd, 0st, second, first, 0th, 0rst, ninth, third,\n",
      "         vix:\t spy, spx, vxx, uvxy, qqq, vx, vvix, tvix,\n",
      "announcement:\t annoucement, announcements, announcment, anouncement, announcing, partnership, pr, aquisition,\n",
      "  securities:\t securi, securit, secu, securiti, securitie, secur, issue, som,\n",
      "distribution:\t senestech, hardwoods, transpiring, aspira, heppened, #marketoutlook, entailed, fd0,\n",
      "        revs:\t revenues, ffo, comps, guides, fy, rev, non-gaap, ebita,\n",
      "         mil:\t mill, 0mil, 0mill, 0million, million, 0m, 0mm, bil,\n",
      "        bull:\t bear, secular, raging, perma, permabull, camp, trap, traps,\n",
      "     bullish:\t bearish, bulish, bulllish, hopeful, bullis, bullsih, skeptical, boolish,\n",
      "        bear:\t bull, raging, perma, secular, panda, permabull, trap, grizzly,\n",
      "     bearish:\t bullish, bulish, negative, permabear, bearis, berish, bullis, bearishness,\n",
      "    breakout:\t break-out, reversal, thrust, breakdown, bullflag, coil, explosion, triangle,\n",
      "      bottom:\t btm, floor, bottoms, top, buttom, dbl, botton, bottem,\n",
      "      bounce:\t bouce, rebound, retrace, bounces, deadcat, dcb, cat, pull,\n",
      "       short:\t ahort, shrt, shorter, short-medium, shor, iborrowdesk, nuven, lomg,\n",
      "       rally:\t sell-off, selloff, meltdown, downturn, swoon, rebound, retreat, plunge,\n",
      "    strength:\t weakness, strenght, resilience, strengh, resiliency, weekness, weakening, hesitation,\n",
      "        nice:\t lovely, sweet, beautiful, neat, decent, awesome, fantastic, great,\n",
      "         dip:\t pullback, dips, oppurtunity, pull-back, dipper, spike, dipp, oportunity,\n",
      "        puts:\t calls, weeklies, leaps, 0calls, otm, lottos, itm, 0puts,\n",
      "        aapl:\t amzn, nflx, baba, msft, appl, googl, nvda, tsla,\n",
      "        down:\t up, dwn, uo, dowm, doen, diwn, dn, to0,\n",
      "    earnings:\t earning, er, earrings, earnigs, er's, 0qfy0, earning's, qtrly,\n",
      "    dividend:\t divi, dividends, divy, divvy, div, payout, distributions, divs,\n",
      "    subpoena:\t whistleblower, subpoenas, foia, decree, panel's, class-action, tort, whistle-blower,\n",
      "    estimate:\t projection, estimation, projected, expectation, forcast, estimated, fy, projections,\n",
      "      volume:\t volumn, vol, volumes, voume, volune, volum, volumen, voulme,\n",
      "        risk:\t reward, risks, asymmetric, risk-reward, gamble, tolerance, mitigation, tradeoff,\n",
      "          :):\t :-), ;), ;-), =), hehe, <winking_face>, (:, glty,\n",
      "    <rocket>:\t <collision>, <chart_increasing>, <airplane>, <comet>, <airplane_departure>, <volcano>, <money_with_wings>, <crescent_moon>,\n",
      "          :(:\t :-(, ugh, ;(, :/, <pensive_face>, :-/, <disappointed_face>, =(,\n",
      "      <fire>:\t <collision>, <chart_increasing>, <high_voltage>, <comet>, <heavy_dollar_sign>, <volcano>, <money_with_wings>, <bomb>,\n"
     ]
    }
   ],
   "source": [
    "evaluate(r\"F:\\w2v_model_dir_8192_shuffle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
